{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced8307c-e499-47ac-acaf-5ff61cf30cbe",
   "metadata": {},
   "source": [
    "### Common Function Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0345ffc3-bda5-49bb-a2d1-5a799b1d3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer, TransformedTargetRegressor, make_column_selector, ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SequentialFeatureSelector,SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8452c70-1e02-41be-a65f-46fb81eb642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Simple function to dump the feature with percentages\n",
    "def feature_null_percentage_in_data(df):\n",
    "    print(round(df.isnull().sum()/df.shape[0] * 100,2))\n",
    "\n",
    "def cleaned_data_percent(df):\n",
    "    cleaned_df = df.dropna()\n",
    "    print(((df.shape[0] - cleaned_df.shape[0])/df.shape[0])* 100)\n",
    "\n",
    "def feature_selection_method(pipeline):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_mse = mean_squared_error(y_train, pipeline.predict(X_train))\n",
    "    print('train_mse : ' , train_mse)\n",
    "    test_mse = mean_squared_error(y_test, pipeline.predict(X_test))\n",
    "    print('test_mse : ', test_mse)\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    print(score)\n",
    "    model_coefs = pipeline.named_steps['ridge'].coef_\n",
    "    feature_names = pipeline.named_steps['selector'].get_feature_names_out()\n",
    "    print(model_coefs)\n",
    "    print(feature_names)\n",
    "    return pd.DataFrame(({'feature' : feature_names, 'coef': model_coefs}))\n",
    "\n",
    "def getFigTitle(fig, title):\n",
    "    fig = fig + 1\n",
    "    return f'Fig{ fig} : {title}', fig\n",
    "\n",
    "def valuecount_percentages(feature_series):\n",
    "    vc_series = feature_series.value_counts()\n",
    "    print('Name             Counts          Percents')\n",
    "    for item in vc_series.index:\n",
    "        print(f\"{item:<15}  \"\n",
    "        f\"{vc_series[item]:<15} \"\n",
    "        f\"{(vc_series[item]/feature_series.size) * 100:.3f}\")\n",
    "    percentage_series = feature_series.value_counts(normalize=True).mul(100).round(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63cd39b2-5144-4c1e-83ce-c48bec12a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Commmon Functions for Data Processing\n",
    "\n",
    "def count_encoder(org_df, categorical_features):\n",
    "    encoder = ce.CountEncoder()\n",
    "    encoded_features = encoder.fit_transform(org_df[categorical_features])\n",
    "    endoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
    "    used_cars_df_encoded = org_df.drop(columns=categorical_features).merge(endoded_df, how='inner', left_index=True, right_index=True).reset_index()\n",
    "    print(used_cars_df_encoded.shape)\n",
    "    used_cars_df_encoded.drop(columns=['index'], inplace=True)\n",
    "    used_cars_df_encoded = pd.DataFrame(scaler.fit_transform(used_cars_df_encoded), columns=used_cars_df_encoded.columns)\n",
    "    used_cars_df_encoded    \n",
    "    return used_cars_df_encoded\n",
    "\n",
    "def run_price_correlation(df):\n",
    "    return df.corrwith(df[\"price\"]).sort_values(ascending=False)\n",
    "\n",
    "def onehot_encoder(org_df, categorical_features):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_features = encoder.fit_transform(org_df[categorical_features])\n",
    "    endoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
    "    print(endoded_df.shape)\n",
    "    used_cars_df_encoded = org_df.merge(endoded_df, how='inner', left_index=True, right_index=True).reset_index()\n",
    "    print(used_cars_df_encoded.shape)\n",
    "    used_cars_df_encoded.drop(columns=['index'], inplace=True)\n",
    "    used_cars_df_encoded.drop(columns=categorical_features, inplace=True)\n",
    "    used_cars_df_encoded = pd.DataFrame(scaler.fit_transform(used_cars_df_encoded), columns=used_cars_df_encoded.columns)\n",
    "    return used_cars_df_encoded    \n",
    "\n",
    "def getX_Y(df):\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price']\n",
    "    return X,y\n",
    "\n",
    "def get_cat_features(df):\n",
    "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "    print('Numerical Features = ', numerical_features)\n",
    "    print('Cateorical Features = ', categorical_features)\n",
    "    return categorical_features\n",
    "def convert_cat_to_codes(df):\n",
    "    new_df = df.copy()\n",
    "    for col_name in new_df.columns:\n",
    "        if(new_df[col_name].dtype == 'object'):\n",
    "            new_df[col_name]= new_df[col_name].astype('category')\n",
    "            new_df[col_name] = new_df[col_name].cat.codes\n",
    "\n",
    "    return new_df\n",
    "\n",
    "pca_names=[]\n",
    "def variance_comp_count(arr_var, ratio):\n",
    "    pca_names.clear()\n",
    "    i = 0\n",
    "    for cumratio in arr_var:\n",
    "        print(f'{ratio}, {cumratio}')\n",
    "        if(ratio < cumratio):\n",
    "            return\n",
    "        else:\n",
    "            pca_names.append(f'pca{i}')\n",
    "            i = i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc8da7e-8a58-4868-a2c8-be51a5d78b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common functions for Pipeline Processing\n",
    "\n",
    "def reset_globals():\n",
    "    models = []\n",
    "    train_mses= []\n",
    "    test_mses = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    train_perms = []\n",
    "    test_perms = []\n",
    "    model_coefs = []\n",
    "    results = []\n",
    "    print('Models = ', models)\n",
    "    print('Result = ', results)\n",
    "\n",
    "\n",
    "def dump_df():\n",
    "    df = {}\n",
    "    df['Models'] = models\n",
    "    df['Train MSE'] = train_mses\n",
    "    df['Test MSE'] = test_mses\n",
    "    df['Train Score'] = train_scores\n",
    "    df['Test Score'] = test_scores\n",
    "    return pd.DataFrame.from_dict(df)\n",
    "\n",
    "def dump_results():\n",
    "    cols = ['model', 'train_mse', 'test_mse', 'train_score', 'test_score']\n",
    "    return pd.DataFrame.from_dict(results)\n",
    "\n",
    "def dump_coefs_df():\n",
    "    return pd.DataFrame(model_coefs, columns=X_train.columns, index=models)\n",
    "\n",
    "def pipeline_proces_and_holdout(pipe, model_name):\n",
    "    print(f'==================== RUNNING {model_name}=================================')\n",
    "    models.append(f'{model_name}-ho')\n",
    "    pipe.fit(X_train, y_train)\n",
    "    train_mse = round(mean_squared_error(y_train, pipe.predict(X_train)), 5)\n",
    "    train_mses.append(train_mse)\n",
    "    test_mse = round(mean_squared_error(y_test, pipe.predict(X_test)), 5)\n",
    "    test_mses.append(test_mse)\n",
    "    train_score = pipe.score(X_train, y_train)\n",
    "    train_scores.append(train_score)\n",
    "    test_score = pipe.score(X_test, y_test)\n",
    "    test_scores.append(test_score)\n",
    "    result = {'model' :f'{model_name}-ho', 'train_mse' : train_mse, 'test_mse' : test_mse, 'train_score' :train_score, 'test_score' :test_score}\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "    print(pipe.named_steps['model'].coef_)\n",
    "    model_coefs.append(pipe.named_steps['model'].coef_)\n",
    "    print('==================== DONE =================================================')\n",
    "\n",
    "def pipeline_proces_and_kfold(pipe, model_name):\n",
    "    print(f'==================== RUNNING {model_name}=================================')\n",
    "    models.append(f'{model_name}-kfold')\n",
    "    kfold = KFold(n_splits=3, random_state=1, shuffle=True)\n",
    "    selector_grid = GridSearchCV(pipe, {}, scoring='r2', cv=kfold, verbose=2)\n",
    "    selector_grid.fit(X_train, y_train)\n",
    "    best_estimator = selector_grid.best_estimator_\n",
    "    best_model = selector_grid.best_estimator_.named_steps['model']\n",
    "    train_mse = round(mean_squared_error(y_train, best_estimator.predict(X_train)), 5)\n",
    "    train_mses.append(train_mse)\n",
    "    test_mse = round(mean_squared_error(y_test, best_estimator.predict(X_test)), 5)\n",
    "    test_mses.append(test_mse)\n",
    "    train_score = best_estimator.score(X_train, y_train)\n",
    "    train_scores.append(train_score)\n",
    "    test_score = best_estimator.score(X_test, y_test)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "#    test_scores.append(list(selector.cv_results_.get('mean_test_score'))[0])\n",
    "    result = {'model' :f'{model_name}-kfold', 'train_mse' : train_mse, 'test_mse' : test_mse, 'train_score' :train_score, 'test_score' :test_score}\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "    print('=====================================================================')\n",
    "    return selector_grid\n",
    "\n",
    "def grid_search_for_best_stuff(pipe, params, X, y):\n",
    "    selector_grid = GridSearchCV(pipe, param_grid=params, verbose=2)\n",
    "    selector_grid.fit(X, y)\n",
    "    selector_grid.cv_results_\n",
    "    best_estimator = selector_grid.best_estimator_\n",
    "    best_model = selector_grid.best_estimator_.named_steps['model']\n",
    "    return selector_grid, best_estimator, best_model, selector_grid.best_estimator_.get_params()\n",
    "\n",
    "def gs_for_number_of_features(pipe, feature_select):\n",
    "    grid, best_estimator, best_model, params = grid_search_for_best_stuff(pipe, feature_select, X_train, y_train)\n",
    "    best_feature_count = params.get('n_features_to_select')\n",
    "    print('best_n_features_to_select = ',best_feature_count)\n",
    "    pipe.set_params(selector__n_features_to_select=best_feature_count)\n",
    "    pipeline_proces_and_holdout(pipe, f'select_fcount-{best_feature_count}')\n",
    "    return grid, best_estimator, best_model, params\n",
    "\n",
    "def gs_for_best_alpha(pipe, ridge_param_dict):\n",
    "    print('=========== Searching for best alpha ====================')\n",
    "    grid, best_estimator, best_model, params = grid_search_for_best_stuff(pipe, ridge_param_dict, X_train, y_train)\n",
    "    best_alpha = round(params.get('model__alpha'),2)\n",
    "    print('best_alpha = ',best_alpha)\n",
    "    pipe.set_params(model__alpha=best_alpha)\n",
    "    pipeline_proces_and_holdout(pipe, f'best_alpha-{best_alpha}')\n",
    "    return best_alpha\n",
    "\n",
    "def getColumnNames(fromName, encoded_names):\n",
    "    arr = []\n",
    "    for i in range(0, fnames.size):\n",
    "        arr.append(X_train.columns[int(fnames[i][1:])])\n",
    "    return arr\n",
    "\n",
    "def dump_hyper_params(hyper_params, best_model_params):\n",
    "    for hp in hyper_params:\n",
    "        print(f'{hp}={best_model_params.get(hp)}')\n",
    "        return best_model_params.get(hp)\n",
    "\n",
    "def selected_columns_list(cols_arr ,selected_list):\n",
    "    selected_columns = []\n",
    "    for i in  range(len(cols_arr)):\n",
    "        if(selected_list[i]):\n",
    "            selected_columns.append(cols_arr[i])\n",
    "    return selected_columns\n",
    "\n",
    "def pipeline_factory(transformer):\n",
    "    linear = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearRegression(fit_intercept=False) )\n",
    "    ])\n",
    "\n",
    "    ridge = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge() )\n",
    "    ])\n",
    "\n",
    "    lasso = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(random_state=rs) )\n",
    "    ])\n",
    "\n",
    "    fs = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SequentialFeatureSelector(LinearRegression(fit_intercept=False))),\n",
    "        ('model', LinearRegression() )\n",
    "    ])\n",
    "\n",
    "    fs_l = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SequentialFeatureSelector(Lasso(random_state=42))),\n",
    "        ('model', LinearRegression() )\n",
    "    ])\n",
    "    \n",
    "    complex = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SequentialFeatureSelector(Lasso(random_state=42))),\n",
    "        ('model', Ridge(random_state=rs))\n",
    "    ])\n",
    "    \n",
    "    ms = Pipeline([\n",
    "        ('transformer',  transformer),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectFromModel(Lasso(random_state=rs))),\n",
    "        ('model', LinearRegression() )\n",
    "    ])\n",
    "    return linear, ridge, lasso, fs, complex, ms, fs_l\n",
    "\n",
    "def dump_feature_imp(pipeline):\n",
    "    r = permutation_importance(pipeline, X_test, y_test, random_state=22, n_repeats=30, scoring='r2')\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            print(f\"{X.columns[i]:<18}  \"\n",
    "            f\"{r.importances_mean[i]:.3f} \"\n",
    "            f\" +/- {r.importances_std[i]:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
